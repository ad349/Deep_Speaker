{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek_dandona/anaconda2/envs/tensorflow/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from models.bioid_cnn_lstm import inference_val\n",
    "from utils import get_filterbanks\n",
    "import bioid\n",
    "import lfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '../new_test/*/*.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folders = glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(folders, columns=['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>speakerid</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../new_test/007029_fisher/007029_fisher@4723_f...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../new_test/007029_fisher/007029_fisher@4723_f...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../new_test/007029_fisher/007029_fisher@4723_f...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../new_test/007029_fisher/007029_fisher@4723_f...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../new_test/007029_fisher/007029_fisher@4723_f...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  speakerid  count\n",
       "0  ../new_test/007029_fisher/007029_fisher@4723_f...          0      5\n",
       "1  ../new_test/007029_fisher/007029_fisher@4723_f...          0      5\n",
       "2  ../new_test/007029_fisher/007029_fisher@4723_f...          0      5\n",
       "3  ../new_test/007029_fisher/007029_fisher@4723_f...          0      5\n",
       "4  ../new_test/007029_fisher/007029_fisher@4723_f...          0      5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['speakerid'] = df.filename.apply(lambda x: x.split('/')[-1].split('@')[0])\n",
    "df['count'] = df.groupby(df['speakerid'])['speakerid'].transform('count')\n",
    "df = df[df['count'] >= 5]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spks = df.speakerid.unique()\n",
    "spk_dct = {spks[i]:i for i in range(len(spks))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['speakerid'] = df.speakerid.apply(lambda x: spk_dct[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = df.sample(1000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speaker_ids = df['speakerid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imposter_id = speaker_ids[:len(speaker_ids)/2]\n",
    "user_id = speaker_ids[len(speaker_ids)/2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_enrollments=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings():\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    # saver=tf.train.Saver()\n",
    "    with tf.Graph().as_default():\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9, allow_growth=True)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,\n",
    "                                                log_device_placement=False,\n",
    "                                                allow_soft_placement=True))\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        with sess.as_default():\n",
    "            bioid.load_model_eval(sess, './models/bioid/20180320-150128/')\n",
    "            waves_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            embeddings = tf.get_default_graph().get_tensor_by_name(\"Graph/L2_Norm/embedding:0\")\n",
    "            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "            batch_size_placeholder = tf.get_default_graph().get_tensor_by_name(\"batch_size:0\")\n",
    "            enrollment_df = pd.DataFrame()\n",
    "            user_df = pd.DataFrame()\n",
    "            print('1')\n",
    "            for i in user_id:\n",
    "                user_temp = df[df['speakerid']==i].reset_index(drop=True)\n",
    "                enrollment_df = pd.concat([enrollment_df,user_temp[:num_enrollments]],axis=0)\n",
    "                user_df = pd.concat([user_df,user_temp[num_enrollments:]],axis=0)\n",
    "            enrollment_df = enrollment_df.reset_index(drop=True)\n",
    "            user_df = user_df.reset_index(drop=True)\n",
    "            imposter_df = pd.DataFrame()\n",
    "            print('2')\n",
    "            for i in imposter_id:\n",
    "                imposter_temp = df[df['speakerid']==i].reset_index(drop=True)\n",
    "                imposter_df = pd.concat([imposter_df,imposter_temp[:num_enrollments]],axis=0)\n",
    "            print('3')\n",
    "            imposter_df = imposter_df.reset_index(drop=True)\n",
    "            eval_xs_enrollment = enrollment_df['filename'].apply(lambda x: get_filterbanks(x))\n",
    "            eval_xs_user = user_df['filename'].apply(lambda x:get_filterbanks(x))\n",
    "            eval_xs_imposter = imposter_df['filename'].apply(lambda x:get_filterbanks(x))\n",
    "            embd_enrollment=[]\n",
    "            embd_user=[]\n",
    "            embd_imposter=[]\n",
    "            print('4')\n",
    "            print('Genrating Embeddings !!')\n",
    "            for eval_x in eval_xs_enrollment:\n",
    "                eval_x = np.expand_dims(eval_x, axis=0)\n",
    "                embd_enrollment.append(sess.run(embeddings,\n",
    "                                                feed_dict={waves_placeholder:eval_x, \n",
    "                                                           phase_train_placeholder:False,\n",
    "                                                           batch_size_placeholder:1}))\n",
    "            for eval_x in eval_xs_user:\n",
    "                eval_x = np.expand_dims(eval_x, axis=0)\n",
    "                embd_user.append(sess.run(embeddings,\n",
    "                                          feed_dict={waves_placeholder:eval_x, \n",
    "                                                     phase_train_placeholder:False,\n",
    "                                                     batch_size_placeholder:1}))\n",
    "            for eval_x in eval_xs_imposter:\n",
    "                eval_x = np.expand_dims(eval_x, axis=0)\n",
    "                embd_imposter.append(sess.run(embeddings,\n",
    "                                              feed_dict={waves_placeholder:eval_x, \n",
    "                                                         phase_train_placeholder:False,\n",
    "                                                         batch_size_placeholder:1}))\n",
    "            print('5')\n",
    "            enrollment_df['embedding']=embd_enrollment\n",
    "            user_df['embedding']=embd_user\n",
    "            imposter_df['embedding']=embd_imposter\n",
    "            sess.close()\n",
    "    return(enrollment_df ,user_df,imposter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: ./models/bioid/20180320-150128/\n",
      "Metagraph file: model-20180320-150128.meta\n",
      "Checkpoint file: model-20180320-150128.ckpt-5822\n",
      "INFO:tensorflow:Restoring parameters from ./models/bioid/20180320-150128/model-20180320-150128.ckpt-5822\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Genrating Embeddings !!\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "enrollment_df ,user_df,imposter_df = get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enrolled_speakers=[]\n",
    "for spk in enrollment_df['speakerid'].unique():\n",
    "    temp=enrollment_df[enrollment_df['speakerid']==spk]\n",
    "    temp_embd=sum(temp['embedding'])/float(len(temp))\n",
    "    enrolled_speakers.append([spk,temp_embd])\n",
    "enrollment_df=pd.DataFrame(enrolled_speakers,columns=['speakerid','embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trials=[]\n",
    "for spk in enrollment_df['speakerid'].unique():\n",
    "    temp=user_df[user_df['speakerid']==spk].reset_index(drop=True)\n",
    "    temp_enrolled=pd.DataFrame()\n",
    "    temp_enrolled['embedding_A']=[enrollment_df[enrollment_df['speakerid']==spk]['embedding'].reset_index(drop=True)[0]]*len(temp)\n",
    "    temp_enrolled['speaker_A']=[spk]*len(temp)\n",
    "    trials.append(pd.concat([temp_enrolled[['embedding_A','speaker_A']],temp[['speakerid','embedding']]],axis=1))\n",
    "    trials.append(pd.concat([temp_enrolled[['embedding_A','speaker_A']],imposter_df.sample(n=len(temp)).reset_index(drop=True)[['speakerid','embedding']]],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_trials=pd.concat(trials).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-bbff2cee7c97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_trials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0membddA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0membddB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0ml2_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membddA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membddB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membddA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membddB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "l2_score=[]\n",
    "target=[]\n",
    "for i in _trials.iterrows():\n",
    "    embddA=i[1][0][0].reshape(1,-1)\n",
    "    embddB=i[1][-1][0].reshape(1,-1)\n",
    "    l2_score.append(euclidean_distances(embddA,embddB)[0][0])\n",
    "    target.append(i[1][1]==i[1][2])\n",
    "_trials['l2_score']=l2_score\n",
    "_trials['target']=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9aabd2d8d044>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_trials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0membddA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0membddB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membddA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "for i in _trials.iterrows():\n",
    "    embddA=i[1][0][0].reshape(1,-1)\n",
    "    embddB=i[1][-1][0].reshape(1,-1)\n",
    "    print(embddA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('EER threshold ', 0.2018967717885971)\n",
      "('EER ', 0.7963483146067416)\n",
      "number of Trials : 1424 \n",
      "number of binary correct predictions 289\n",
      "Binary classification AUC : 0.203\n"
     ]
    }
   ],
   "source": [
    "# eer_threshold=0.79114027661991715\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, threshold = roc_curve(_trials['target'].apply(lambda x:1 if x else 0),\n",
    "                                _trials['l2_score'],pos_label=1)\n",
    "fnr = 1 - tpr\n",
    "eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "print('EER threshold ',eer_threshold)\n",
    "EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "print('EER ',EER)\n",
    "\n",
    "print('number of Trials : %d '%len(_trials['target']))\n",
    "print('number of binary correct predictions %d'%sum((_trials['target'])==(_trials['l2_score']>eer_threshold)))\n",
    "auc=sum((_trials['target'])==(_trials['l2_score']>eer_threshold))/float(len(_trials['target']))\n",
    "print('Binary classification AUC : %1.3f'%auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.Graph().as_default():\n",
    "#     with  tf.Session() as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         bioid.load_model('./models/bioid/20180124-173845/')\n",
    "#         x = [n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.7",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
