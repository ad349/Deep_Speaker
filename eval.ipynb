{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek_dandona/anaconda2/envs/tensorflow/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from models.bioid_cnn_lstm import inference_val\n",
    "from utils import get_filterbanks\n",
    "import bioid\n",
    "import lfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '../test_2/*/*.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folders = glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(folders, columns=['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>speakerid</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../test_2/001060_voxforge/001060_voxforge@a049...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../test_2/001060_voxforge/001060_voxforge@a049...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../test_2/001060_voxforge/001060_voxforge@a050...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../test_2/001060_voxforge/001060_voxforge@a049...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../test_2/001060_voxforge/001060_voxforge@a049...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  speakerid  count\n",
       "0  ../test_2/001060_voxforge/001060_voxforge@a049...          0      9\n",
       "1  ../test_2/001060_voxforge/001060_voxforge@a049...          0      9\n",
       "2  ../test_2/001060_voxforge/001060_voxforge@a050...          0      9\n",
       "3  ../test_2/001060_voxforge/001060_voxforge@a049...          0      9\n",
       "4  ../test_2/001060_voxforge/001060_voxforge@a049...          0      9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['speakerid'] = df.filename.apply(lambda x: x.split('/')[-1].split('@')[0])\n",
    "df['count'] = df.groupby(df['speakerid'])['speakerid'].transform('count')\n",
    "df = df[df['count'] >= 5]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spks = df.speakerid.unique()\n",
    "spk_dct = {spks[i]:i for i in range(len(spks))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['speakerid'] = df.speakerid.apply(lambda x: spk_dct[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = df.sample(1000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speaker_ids = df['speakerid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imposter_id = speaker_ids[:len(speaker_ids)/2]\n",
    "user_id = speaker_ids[len(speaker_ids)/2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_enrollments=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings():\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    # saver=tf.train.Saver()\n",
    "    with tf.Graph().as_default():\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9, allow_growth=True)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,\n",
    "                                                log_device_placement=False,\n",
    "                                                allow_soft_placement=True))\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        with sess.as_default():\n",
    "            with tf.device('/gpu:0'):\n",
    "                bioid.load_model_eval(sess, './models/bioid/20180315-113504/')\n",
    "                waves_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "                embeddings = tf.get_default_graph().get_tensor_by_name(\"L2_Norm/embedding:0\")\n",
    "                phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "                batch_size_placeholder = tf.get_default_graph().get_tensor_by_name(\"batch_size:0\")\n",
    "                enrollment_df = pd.DataFrame()\n",
    "                user_df = pd.DataFrame()\n",
    "                print('1')\n",
    "                for i in user_id:\n",
    "                    user_temp = df[df['speakerid']==i].reset_index(drop=True)\n",
    "                    enrollment_df = pd.concat([enrollment_df,user_temp[:num_enrollments]],axis=0)\n",
    "                    user_df = pd.concat([user_df,user_temp[num_enrollments:]],axis=0)\n",
    "                enrollment_df = enrollment_df.reset_index(drop=True)\n",
    "                user_df = user_df.reset_index(drop=True)\n",
    "                imposter_df = pd.DataFrame()\n",
    "                print('2')\n",
    "                for i in imposter_id:\n",
    "                    imposter_temp = df[df['speakerid']==i].reset_index(drop=True)\n",
    "                    imposter_df = pd.concat([imposter_df,imposter_temp[:num_enrollments]],axis=0)\n",
    "                print('3')\n",
    "                imposter_df = imposter_df.reset_index(drop=True)\n",
    "                eval_xs_enrollment = enrollment_df['filename'].apply(lambda x: get_filterbanks(x))\n",
    "                eval_xs_user = user_df['filename'].apply(lambda x:get_filterbanks(x))\n",
    "                eval_xs_imposter = imposter_df['filename'].apply(lambda x:get_filterbanks(x))\n",
    "                embd_enrollment=[]\n",
    "                embd_user=[]\n",
    "                embd_imposter=[]\n",
    "                print('4')\n",
    "                print('Genrating Embeddings !!')\n",
    "                for eval_x in eval_xs_enrollment:\n",
    "                    eval_x = np.expand_dims(eval_x, axis=0)\n",
    "                    embd_enrollment.append(sess.run(embeddings,\n",
    "                                                    feed_dict={waves_placeholder:eval_x, \n",
    "                                                               phase_train_placeholder:False,\n",
    "                                                               batch_size_placeholder:1}))\n",
    "                for eval_x in eval_xs_user:\n",
    "                    eval_x = np.expand_dims(eval_x, axis=0)\n",
    "                    embd_user.append(sess.run(embeddings,\n",
    "                                              feed_dict={waves_placeholder:eval_x, \n",
    "                                                         phase_train_placeholder:False,\n",
    "                                                         batch_size_placeholder:1}))\n",
    "                for eval_x in eval_xs_imposter:\n",
    "                    eval_x = np.expand_dims(eval_x, axis=0)\n",
    "                    embd_imposter.append(sess.run(embeddings,\n",
    "                                                  feed_dict={waves_placeholder:eval_x, \n",
    "                                                             phase_train_placeholder:False,\n",
    "                                                             batch_size_placeholder:1}))\n",
    "                print('5')\n",
    "                enrollment_df['embedding']=embd_enrollment\n",
    "                user_df['embedding']=embd_user\n",
    "                imposter_df['embedding']=embd_imposter\n",
    "                sess.close()\n",
    "    return(enrollment_df ,user_df,imposter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: ./models/bioid/20180315-113504/\n",
      "Metagraph file: model-20180315-113504.meta\n",
      "Checkpoint file: model-20180315-113504.ckpt-1106\n",
      "INFO:tensorflow:Restoring parameters from ./models/bioid/20180315-113504/model-20180315-113504.ckpt-1106\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "enrollment_df ,user_df,imposter_df = get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enrolled_speakers=[]\n",
    "for spk in enrollment_df['speakerid'].unique():\n",
    "    temp=enrollment_df[enrollment_df['speakerid']==spk]\n",
    "    temp_embd=sum(temp['embedding'])/float(len(temp))\n",
    "    enrolled_speakers.append([spk,temp_embd])\n",
    "enrollment_df=pd.DataFrame(enrolled_speakers,columns=['speakerid','embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trials=[]\n",
    "for spk in enrollment_df['speakerid'].unique():\n",
    "    temp=user_df[user_df['speakerid']==spk].reset_index(drop=True)\n",
    "    temp_enrolled=pd.DataFrame()\n",
    "    temp_enrolled['embedding_A']=[enrollment_df[enrollment_df['speakerid']==spk]['embedding'].reset_index(drop=True)[0]]*len(temp)\n",
    "    temp_enrolled['speaker_A']=[spk]*len(temp)\n",
    "    trials.append(pd.concat([temp_enrolled[['embedding_A','speaker_A']],temp[['speakerid','embedding']]],axis=1))\n",
    "    trials.append(pd.concat([temp_enrolled[['embedding_A','speaker_A']],imposter_df.sample(n=len(temp)).reset_index(drop=True)[['speakerid','embedding']]],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_trials=pd.concat(trials).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cosine_score=[]\n",
    "target=[]\n",
    "for i in _trials.iterrows():\n",
    "    embddA=i[1][0][0].reshape(1,-1)\n",
    "    embddB=i[1][-1][0].reshape(1,-1)\n",
    "    cosine_score.append(cosine_similarity(embddA,embddB)[0][0])\n",
    "    target.append(i[1][1]==i[1][2])\n",
    "_trials['cosine_score']=cosine_score\n",
    "_trials['target']=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eer_threshold=0.79114027661991715\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, threshold = roc_curve(_trials['target'].apply(lambda x:1 if x else 0),\n",
    "                                _trials['cosine_score'],pos_label=1)\n",
    "fnr = 1 - tpr\n",
    "eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "print('EER threshold ',eer_threshold)\n",
    "EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "print('EER ',EER)\n",
    "\n",
    "print('number of Trials : %d '%len(_trials['target']))\n",
    "print('number of binary correct predictions %d'%sum((_trials['target'])==(_trials['cosine_score']>eer_threshold)))\n",
    "auc=sum((_trials['target'])==(_trials['cosine_score']>eer_threshold))/float(len(_trials['target']))\n",
    "print('Binary classification AUC : %1.3f'%auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.Graph().as_default():\n",
    "#     with  tf.Session() as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         bioid.load_model('./models/bioid/20180124-173845/')\n",
    "#         x = [n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.7",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
